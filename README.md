# ğŸ”¬ Skin Lesion Classification & Localization using Grad-CAM

A comprehensive deep learning project for automated skin lesion classification with explainable AI visualization using Grad-CAM. This project combines multimodal data (dermoscopic images + clinical features) for accurate diagnosis and provides interpretable results through attention heatmaps.

## ğŸŒŸ Features

- ğŸ”¬ **Multimodal Classification**: Combines dermoscopic images, MONET clinical features, and patient metadata
- ğŸ”¥ **Grad-CAM Visualization**: Explainable AI showing which image regions influence predictions
- ğŸ“Š **Interactive Demo**: Streamlit web application for real-time classification and visualization
- ğŸ¯ **11-Class Classification**: Comprehensive skin lesion type detection
- ğŸ“ˆ **High Performance**: EfficientNet-B3 backbone with multimodal fusion architecture

## ğŸ“‹ Supported Lesion Classes

| Class | Full Name | Description |
|-------|-----------|-------------|
| **AKIEC** | Actinic Keratoses | Precancerous skin lesions |
| **BCC** | Basal Cell Carcinoma | Most common skin cancer |
| **BEN_OTH** | Benign Other | Non-cancerous lesions |
| **BKL** | Benign Keratosis-like | Harmless skin growths |
| **DF** | Dermatofibroma | Benign fibrous nodules |
| **INF** | Inflammatory | Inflammatory conditions |
| **MAL_OTH** | Malignant Other | Other skin cancers |
| **MEL** | Melanoma | Most dangerous skin cancer |
| **NV** | Melanocytic Nevus | Common moles |
| **SCCKA** | Squamous Cell Carcinoma | Second most common skin cancer |
| **VASC** | Vascular Lesions | Blood vessel-related marks |

## ğŸš€ Quick Start

### Prerequisites
- Python 3.7+ 
- CUDA-compatible GPU (recommended) or CPU
- Git (for cloning)

### 1. Clone Repository
```bash
git clone https://github.com/ChintaSuryaTeja/Lesion-Classification-Localization-using-GradCAM.git
cd Lesion-Classification-Localization-using-GradCAM
```

### 2. Setup Virtual Environment
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Download Model Weights
**Important**: You need to obtain the trained model file `best_multimodal_effb3.pth` and place it in the project root directory. This file is not included in the repository due to size constraints.

### 5. Run the Streamlit Demo

#### Option A: Using Scripts (Windows)
```cmd
# Batch file
run_demo.bat

# Or PowerShell
.\run_demo.ps1
```

#### Option B: Direct Command
```bash
streamlit run app.py
```

#### Option C: Using Python Module
```bash
python -m streamlit run app.py
```

### 6. Access the Application
- The app will automatically open in your browser
- Default URL: `http://localhost:8501`
- Upload dermoscopic images and view real-time classification results!

## How to Use

1. **Upload Image**: Click "Choose a dermoscopic image..." and select a JPG, JPEG, or PNG file
2. **Wait for Analysis**: The model will process the image and generate predictions
3. **View Results**: 
   - See the original image and Grad-CAM overlay
   - Check the predicted class and confidence level
   - Review probability scores for all classes
4. **Interpret Grad-CAM**: Red areas in the overlay indicate regions that most influenced the prediction

## Model Architecture

The demo uses a **MultimodalEfficientNetB3** model that combines:
- **Image features** from EfficientNet-B3 backbone
- **MONET clinical features** (7 morphological descriptors)
- **Metadata** (age, sex, skin tone, anatomical site)

*Note: In this demo, default values are used for MONET and metadata features since they're not available from image upload alone.*

## Important Disclaimers

âš ï¸ **FOR RESEARCH AND DEMONSTRATION PURPOSES ONLY**

- This is NOT a medical device or diagnostic tool
- Do NOT use for actual medical diagnosis
- Always consult qualified healthcare professionals
- The model uses simplified default clinical features in demo mode

## Technical Requirements

- Python 3.7+
- CUDA-capable GPU (recommended) or CPU
- Web browser with JavaScript enabled
- Trained model file (`best_multimodal_effb3.pth`)

## ğŸ”§ Troubleshooting

### Common Issues & Solutions

| Issue | Solution |
|-------|----------|
| ğŸš« **Model file not found** | Download `best_multimodal_effb3.pth` and place in project root |
| âš¡ **CUDA errors** | App automatically falls back to CPU processing |
| ğŸ’¾ **Memory errors** | Use smaller images or restart application |
| ğŸ“¦ **Import errors** | Ensure virtual environment is activated: `pip install -r requirements.txt` |
| ğŸŒ **Streamlit not found** | Run: `pip install streamlit` in activated environment |
| ğŸ”— **Port already in use** | Streamlit will automatically use next available port |

### ğŸ†˜ Getting Help

1. âœ… **Check Prerequisites**: Virtual environment activated, all dependencies installed
2. ğŸ“ **Verify Files**: Model file present and accessible  
3. ğŸ–¥ï¸ **Check Console**: Review terminal/console for detailed error messages
4. ğŸ› **Debug Mode**: Add `--logger.level debug` to streamlit command
5. ğŸ’¬ **Report Issues**: Create GitHub issue with error details and system info

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

### Development Setup
```bash
# Fork and clone the repository
git clone https://github.com/YOUR_USERNAME/Lesion-Classification-Localization-using-GradCAM.git
cd Lesion-Classification-Localization-using-GradCAM

# Create development environment
python -m venv dev-env
source dev-env/bin/activate  # or dev-env\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
```

### Contribution Areas
- ğŸ¨ **UI/UX Improvements**: Enhance Streamlit interface
- ğŸ§  **Model Enhancements**: Implement new architectures or training techniques  
- ğŸ“Š **Visualization**: Add new interpretation methods (ScoreCAM, LayerCAM)
- ğŸ”¬ **Medical Features**: Integrate additional clinical data modalities
- ğŸ“š **Documentation**: Improve guides, add tutorials
- ğŸ› **Bug Fixes**: Report and fix issues

### Pull Request Process
1. ğŸ”€ Create feature branch: `git checkout -b feature/amazing-feature`
2. ğŸ’» Make changes and test thoroughly
3. ğŸ“ Update documentation if needed
4. âœ… Ensure code follows project style
5. ğŸ“¤ Submit pull request with clear description

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **MILK10k Dataset**: International Skin Imaging Collaboration (ISIC)
- **EfficientNet**: Google Research team
- **Grad-CAM**: Selvaraju et al. (2017)
- **Streamlit**: Amazing framework for ML web apps

## ğŸ“š Citation

If you use this project in your research, please cite:

```bibtex
@misc{lesion-classification-gradcam-2025,
  title={Skin Lesion Classification and Localization using Grad-CAM},
  author={Chinta Surya Teja},
  year={2025},
  url={https://github.com/ChintaSuryaTeja/Lesion-Classification-Localization-using-GradCAM}
}
```

---

**âš ï¸ Medical Disclaimer**: This software is for research and educational purposes only. It is not intended for medical diagnosis or clinical decision-making. Always consult qualified healthcare professionals for medical advice.

## ğŸ—ï¸ Project Structure

```
Lesion-Classification-Localization-using-GradCAM/
â”œâ”€â”€ ğŸ“± Frontend & Demo
â”‚   â”œâ”€â”€ app.py                 # Streamlit web application
â”‚   â”œâ”€â”€ run_demo.bat          # Windows batch launcher
â”‚   â””â”€â”€ run_demo.ps1          # PowerShell launcher
â”‚
â”œâ”€â”€ ğŸ§  Model & Training
â”‚   â”œâ”€â”€ model.py              # MultimodalEfficientNetB3 architecture
â”‚   â”œâ”€â”€ train.py              # Training script
â”‚   â””â”€â”€ best_multimodal_effb3.pth  # Trained model weights (download required)
â”‚
â”œâ”€â”€ ğŸ“Š Analysis & Notebooks
â”‚   â”œâ”€â”€ train.ipynb           # Training notebook
â”‚   â”œâ”€â”€ dataset.ipynb         # Data preprocessing
â”‚   â””â”€â”€ gradCam.ipynb         # Grad-CAM analysis
â”‚
â”œâ”€â”€ ğŸ“ Data & Outputs
â”‚   â”œâ”€â”€ dataset/              # MILK10k dataset (not included)
â”‚   â”œâ”€â”€ gradcam_outputs/      # Generated visualizations
â”‚   â”œâ”€â”€ scorecam_outputs/     # Alternative CAM outputs
â”‚   â””â”€â”€ *.csv                 # Processed dataset files
â”‚
â”œâ”€â”€ âš™ï¸ Configuration
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â”œâ”€â”€ .gitignore           # Git ignore rules
â”‚   â””â”€â”€ README.md            # This documentation
```

## ğŸ§¬ Model Architecture

The **MultimodalEfficientNetB3** combines three data streams:

### ğŸ–¼ï¸ Image Branch
- **Backbone**: EfficientNet-B3 (ImageNet pretrained)
- **Input**: 300Ã—300 RGB dermoscopic images
- **Output**: 512-dimensional image features

### ğŸ¥ Clinical Branch (MONET)
- **Features**: 7 morphological descriptors
  - Ulceration/crust, Hair, Vasculature, Erythema
  - Pigmentation, Gel/fluid, Skin markings
- **Architecture**: MLP (7 â†’ 128 features)

### ğŸ‘¤ Metadata Branch  
- **Features**: Patient demographics & lesion location
  - Age, Sex, Skin tone, Anatomical site
- **Architecture**: MLP (4 â†’ 32 features)

### ğŸ”— Fusion Layer
- **Input**: Concatenated features (512 + 128 + 32 = 672)
- **Output**: 11-class probability distribution
- **Loss**: Class-weighted CrossEntropy (handles imbalanced data)

## ğŸ¯ Training Details

- **Dataset**: MILK10k (5,000+ training samples)
- **Optimization**: AdamW (lr=2e-4)
- **Regularization**: Mixed precision training, dropout, data augmentation
- **Hardware**: CUDA GPU recommended
- **Epochs**: 20 with early stopping

## Model Performance

The model was trained on the MILK10k dataset and uses:
- Multimodal fusion architecture
- Class-weighted loss for imbalanced data
- Mixed precision training
- Grad-CAM for interpretability

For detailed model information, see the training scripts and notebooks in the project.